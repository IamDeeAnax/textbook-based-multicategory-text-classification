{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ETDlZiZJoqyXMlNmNQ8MpHNNcy-Zp5Dr#scrollTo=KSXZXY7SOJeW)\n"
      ],
      "metadata": {
        "id": "KSXZXY7SOJeW"
      },
      "id": "KSXZXY7SOJeW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing packages\n",
        "\n",
        "pip install wordninja==2.0.0 numpy==1.22.4 contractions==0.1.73 nltk==3.8.1 tensorflow==2.12.0 tensorflow-text==2.12.1 tensorflow-hub==0.13.0 matplotlib==3.7.1 seaborn==0.12.2 scikit-learn==1.2.2 plotly==5.13.1 PyMuPDF==1.22.1 bert-for-tf2==0.14.9 requests==2.27.1 pandas==1.5.3 wordcloud==1.8.2.2\n"
      ],
      "metadata": {
        "id": "45OqkibBQ6ye"
      },
      "id": "45OqkibBQ6ye",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing librabries\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import fitz\n",
        "import glob\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words\n",
        "import wordninja\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import seaborn as sns\n",
        "from plotly.offline import iplot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, roc_auc_score,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             cohen_kappa_score, matthews_corrcoef, classification_report)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "TnBuZawwgPzK"
      },
      "id": "TnBuZawwgPzK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of download links and corresponding file names\n",
        "download_links = [\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1-_WoifNaLCaxcEwyTl865589E3m4qAxS', 'filename': 'Biology1.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1wmfh8CkrMWjyOvNkXrsymmw3PmFomOUB', 'filename': 'Biology2.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=16u0trx49fQvYGYmz6N7egNAaWE6zxFAQ', 'filename': 'Computer_Science1.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1S6DkHjHUzNzmVHdp4bgz7Lpxb16ZXEy2', 'filename': 'Computer_Science2.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1Va109nfuG2U68qeH2FlNJ3uZOXAqjnpO', 'filename': 'Computer_Science3.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=19CKD4K1uyngyafUI8_uFaiD0w71F4COx', 'filename': 'Computer_Science4.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1zarC3y6BdQqY3j7mjRPBletmkVg6yBHh', 'filename': 'Computer_Science5.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1dsunh17Z72hxjffVhum36AhnKCIjt4ys', 'filename': 'History1.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1t92NXqBp4htdCdO14DKzrnzdAklIxFPp', 'filename': 'History2.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1K-CIzcw4rhapwA7v4MbJtX755PwJva_b', 'filename': 'History3.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1XUCBVhbCAYasVLjtZGVM0OQGuHNUlDTJ', 'filename': 'History4.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1q7iAHeIhAxNXA3O__SwZJ8IruzOSoOyf', 'filename': 'History5.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1EeITsFsc5g40mBg3EwT9F8DeG5KKnEML', 'filename': 'History6.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1mU25GRO0SrTFPy44PPquXmMEOrPRGbic', 'filename': 'Physics1.pdf'},\n",
        "    {'url': 'https://drive.google.com/uc?export=download&id=1nqtPR81L9BExsu4lBTS7J_sHiErAyygb', 'filename': 'Physics2.pdf'}\n",
        "]\n",
        "\n",
        "# Loop through the download links and download each file\n",
        "for item in download_links:\n",
        "    url = item['url']\n",
        "    filename = item['filename']\n",
        "\n",
        "    try:\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(filename, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "        print(f\"Downloaded {filename}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "ZEgIbAMHQXB8"
      },
      "id": "ZEgIbAMHQXB8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the text from the pdf file\n",
        "\n",
        "def split_text(text):\n",
        "    words = text.split()\n",
        "    half = len(words) // 2\n",
        "    return ' '.join(words[:half]), ' '.join(words[half:])\n",
        "\n",
        "def is_empty_file(file_path):\n",
        "    return os.path.getsize(file_path) == 0\n",
        "\n",
        "def remove_empty_file(file_path):\n",
        "    if is_empty_file(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "def extract_text(pdf_file, subject_dir):\n",
        "    os.makedirs(subject_dir, exist_ok=True)\n",
        "    merged_text = \"\"\n",
        "\n",
        "    try:\n",
        "        with fitz.open(pdf_file) as pdf:\n",
        "            for i, page in enumerate(pdf):\n",
        "                text = page.get_text()\n",
        "                words = text.split()\n",
        "                if len(words) < 100:\n",
        "                    merged_text += \" \" + text\n",
        "                    continue\n",
        "\n",
        "                if merged_text:\n",
        "                    half1, half2 = split_text(merged_text)\n",
        "                    file1_path = os.path.join(subject_dir, f'{os.path.splitext(os.path.basename(pdf_file))[0]}_merged_part1.txt')\n",
        "                    with open(file1_path, 'w') as f1:\n",
        "                        f1.write(half1)\n",
        "                    remove_empty_file(file1_path)\n",
        "\n",
        "                    file2_path = os.path.join(subject_dir, f'{os.path.splitext(os.path.basename(pdf_file))[0]}_merged_part2.txt')\n",
        "                    with open(file2_path, 'w') as f2:\n",
        "                        f2.write(half2)\n",
        "                    remove_empty_file(file2_path)\n",
        "                    merged_text = \"\"\n",
        "\n",
        "                half1, half2 = split_text(text)\n",
        "\n",
        "                file1_path = os.path.join(subject_dir, f'{os.path.splitext(os.path.basename(pdf_file))[0]}_page_{i+1}_part1.txt')\n",
        "                with open(file1_path, 'w') as f1:\n",
        "                    f1.write(half1)\n",
        "                remove_empty_file(file1_path)\n",
        "\n",
        "                file2_path = os.path.join(subject_dir, f'{os.path.splitext(os.path.basename(pdf_file))[0]}_page_{i+1}_part2.txt')\n",
        "                with open(file2_path, 'w') as f2:\n",
        "                    f2.write(half2)\n",
        "                remove_empty_file(file2_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_file}: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    base_dir = \"Dataset\"\n",
        "    subject_files = {\n",
        "        'Computer_Science': [\n",
        "            './Computer_Science1.pdf',\n",
        "            './Computer_Science2.pdf',\n",
        "            './Computer_Science3.pdf',\n",
        "            './Computer_Science4.pdf',\n",
        "            './Computer_Science5.pdf',\n",
        "        ],\n",
        "        'Physics': [\n",
        "            './Physics1.pdf',\n",
        "            './Physics2.pdf'\n",
        "        ],\n",
        "        'Biology': [\n",
        "            './Biology1.pdf',\n",
        "            './Biology2.pdf'\n",
        "        ],\n",
        "        'History': [\n",
        "            './History1.pdf',\n",
        "            './History2.pdf',\n",
        "            './History3.pdf',\n",
        "            './History4.pdf',\n",
        "            './History5.pdf',\n",
        "            './History6.pdf'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    for subject, pdf_files in subject_files.items():\n",
        "        print(f\"Extracting text for {subject}\")\n",
        "        subject_dir = os.path.join(base_dir, subject)\n",
        "        for pdf_file in pdf_files:\n",
        "            extract_text(pdf_file, subject_dir)"
      ],
      "metadata": {
        "id": "yLobXzrSTy-P"
      },
      "id": "yLobXzrSTy-P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d875b04",
      "metadata": {
        "id": "6d875b04"
      },
      "outputs": [],
      "source": [
        "# Reads the extracted text data from multiple text files located in subfolders of a specified directory and appends the text data to data list and corresponding categories to category list.\n",
        "\n",
        "data = []\n",
        "category = []\n",
        "\n",
        "# Set the path to the folder containing subfolders\n",
        "path = os.path.expanduser(\"./Dataset\")\n",
        "\n",
        "# Loop over the subfolders and their contents\n",
        "for folder in os.listdir(path):\n",
        "    folder_path = os.path.join(path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file_path in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
        "            # Read the text data from the file\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "            # Append the text and category to the data and labels lists\n",
        "            data.append(text)\n",
        "            category.append(folder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of datapoints in the dataset\n",
        "num_datapoints = len(data)\n",
        "\n",
        "# Print the number of datapoints\n",
        "print('Number of datapoints:', num_datapoints)"
      ],
      "metadata": {
        "id": "_iKubm-QDuV3"
      },
      "id": "_iKubm-QDuV3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d03496",
      "metadata": {
        "id": "15d03496"
      },
      "outputs": [],
      "source": [
        "# Print first hundred data list\n",
        "\n",
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32933988",
      "metadata": {
        "id": "32933988"
      },
      "outputs": [],
      "source": [
        "# Print first two categories\n",
        "\n",
        "category[:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download punkt and stopwords dataset from nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "UJbK41OELEs1"
      },
      "id": "UJbK41OELEs1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download words dataset from nltk\n",
        "nltk.download('words')\n",
        "\n",
        "# Load the set of English words\n",
        "english_words = set(words.words())"
      ],
      "metadata": {
        "id": "m-k4zxouY6MB"
      },
      "id": "m-k4zxouY6MB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to preprocess the data\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Remove newlines\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "\n",
        "    # Remove hyphens and put spaces\n",
        "    text = re.sub(r'-', ' ', text)\n",
        "\n",
        "    # Remove words containing numbers\n",
        "    text = re.sub(r'\\b\\w*\\d\\w*\\b', ' ', text)\n",
        "\n",
        "    # Replace one or two letter words with an empty string\n",
        "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
        "\n",
        "    # Remove Roman numerals\n",
        "    text = re.sub(r'\\b[IVXLCDM]+\\b', ' ', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Separate joined words\n",
        "    text = ' '.join(wordninja.split(text))\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', ' ', text)\n",
        "\n",
        "    # Remove any special characters\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "    # Replace duplicate word with single word\n",
        "    text = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]|_', ' ', text)\n",
        "\n",
        "    # Remove specific words\n",
        "    text = re.sub(r'\\b(?:one|two|use|also|would|first|fig|may|used|see|new|differennt|called|many|find|part|number|using|work|chapter|example|must|true|cos|false|within|result|much|another|figure|form|three|like|however|given)\\b', \" \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\b(?:oh|ost|coo|coa|syn|yl|lih|gre|sni|tait|al|ce|ten|elo|oid|ley|rer|se|isra|blu|lk|lu|ree|lt|lus|lu|el|line|thus|end|process|change|different|could)\\b', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove single alphabets excluding \"a\"\n",
        "    text = re.sub(r\"(?<![a-zA-Z])[^aA\\s][^a-zA-Z]?(?![a-zA-Z])\", \"\", text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "T3WpVqOi4OAg"
      },
      "id": "T3WpVqOi4OAg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function\n",
        "\n",
        "preprocessed_data = [preprocess_text(text) for text in data]"
      ],
      "metadata": {
        "id": "JFnL20qUL52n"
      },
      "id": "JFnL20qUL52n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the data before preprocessing\n",
        "\n",
        "data[12100:12200]"
      ],
      "metadata": {
        "id": "o3cKviBQf-T2"
      },
      "id": "o3cKviBQf-T2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the data after preprocessing\n",
        "\n",
        "preprocessed_data[12100:12200]"
      ],
      "metadata": {
        "id": "e4jmEhgxMKTv"
      },
      "id": "e4jmEhgxMKTv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of stop words\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Count the occurrences of each stop word in the datasets\n",
        "stop_word_counts = Counter([word for dataset in preprocessed_data for word in dataset.split() if word in stop_words])\n",
        "\n",
        "# Get the 10 most common stop words\n",
        "most_common_stop_words = stop_word_counts.most_common(10)\n",
        "\n",
        "# Plot the graph\n",
        "plt.bar([word[0] for word in most_common_stop_words], [word[1] for word in most_common_stop_words])\n",
        "plt.title('Most common stop words')\n",
        "plt.xlabel('Stop word')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oZPmQGXtQqKd"
      },
      "id": "oZPmQGXtQqKd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each stop word in the datasets\n",
        "word_counts = Counter([word for text in preprocessed_data for word in text.split() if word not in stop_words])\n",
        "\n",
        "# Get the 35 most common words\n",
        "most_common_words = word_counts.most_common(35)\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "# Plot the graph\n",
        "plt.bar([word[0] for word in most_common_words], [word[1] for word in most_common_words])\n",
        "plt.title('Most common words')\n",
        "plt.xlabel('Word')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Dh3SpARDs3b"
      },
      "id": "_Dh3SpARDs3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the preprocessed data and corresponding category\n",
        "df = pd.DataFrame({'preprocessed_data': preprocessed_data, 'Category': category})\n",
        "\n",
        "# Filter your data based on each label\n",
        "data_biology = df[df['Category'] == 'Biology']['preprocessed_data']\n",
        "data_computer_science = df[df['Category'] == 'Computer_Science']['preprocessed_data']\n",
        "data_history = df[df['Category'] == 'History']['preprocessed_data']\n",
        "data_physics = df[df['Category'] == 'Physics']['preprocessed_data']"
      ],
      "metadata": {
        "id": "DwZ1j_KNWdY1"
      },
      "id": "DwZ1j_KNWdY1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create wordcloud\n",
        "def create_word_cloud(data, label):\n",
        "    # Join the different processed texts together\n",
        "    long_string = ','.join(data)\n",
        "\n",
        "    # Create a WordCloud object\n",
        "    wordcloud = WordCloud(background_color=\"black\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
        "\n",
        "    # Generate a word cloud\n",
        "    wordcloud.generate(long_string)\n",
        "\n",
        "    # Visualize the word cloud\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Word Cloud for {label}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "lI-EGVb0XNR4"
      },
      "id": "lI-EGVb0XNR4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a word cloud for each category\n",
        "create_word_cloud(data_biology, 'Biology')\n",
        "create_word_cloud(data_computer_science, 'Computer_Science')\n",
        "create_word_cloud(data_history, 'History')\n",
        "create_word_cloud(data_physics, 'Physics')"
      ],
      "metadata": {
        "id": "g8ZMK9OwXT7Z"
      },
      "id": "g8ZMK9OwXT7Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the number of words in each sentence of the proccessed data\n",
        "count_sent_word = [len(sentence.split()) for sentence in preprocessed_data]\n",
        "\n",
        "# Visualize it\n",
        "plt.figure(figsize=(8, 10))\n",
        "\n",
        "sns.displot(count_sent_word)\n",
        "\n",
        "plt.xlim(0, 800)\n",
        "\n",
        "plt.xlabel(\"The number of words\", fontsize=14)\n"
      ],
      "metadata": {
        "id": "IdOB0bHlPMa3"
      },
      "id": "IdOB0bHlPMa3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the length of each text document\n",
        "document_lengths = [len(doc) for doc in preprocessed_data]\n",
        "\n",
        "# Plot a histogram of document lengths\n",
        "plt.hist(document_lengths)\n",
        "plt.xlabel(\"Document length (number of characters)\")\n",
        "plt.ylabel(\"Number of documents\")\n",
        "plt.title(\"Distribution of document lengths\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sWgq20Vw9KbJ"
      },
      "id": "sWgq20Vw9KbJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the unique categories\n",
        "\n",
        "topic_count = pd.Series(category).value_counts()\n",
        "\n",
        "topic_categories = topic_count.index.tolist()\n",
        "\n",
        "print(topic_categories)\n"
      ],
      "metadata": {
        "id": "uZUKdBAU8D-P"
      },
      "id": "uZUKdBAU8D-P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c32f531",
      "metadata": {
        "id": "3c32f531"
      },
      "outputs": [],
      "source": [
        "# Number of categories\n",
        "\n",
        "num_class = len(set(category))\n",
        "\n",
        "print(\"Number of Categories:\", num_class)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_count = pd.Series(category).value_counts()\n",
        "topic_count"
      ],
      "metadata": {
        "id": "_TSEaIJfdUya"
      },
      "id": "_TSEaIJfdUya",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the count of each category\n",
        "\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "sns.barplot(x=topic_categories, y=topic_count)\n"
      ],
      "metadata": {
        "id": "L7CCumLD8bze"
      },
      "id": "L7CCumLD8bze",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words from each sentence\n",
        "filtered_text_data = []\n",
        "for sentence in preprocessed_data:\n",
        "    filtered_sentence = \" \".join([word for word in sentence.split() if word.lower() not in stop_words])\n",
        "    filtered_text_data.append(filtered_sentence)"
      ],
      "metadata": {
        "id": "Nknrf21M5yQZ"
      },
      "id": "Nknrf21M5yQZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_text_data"
      ],
      "metadata": {
        "id": "3kwE6cex6uCe"
      },
      "id": "3kwE6cex6uCe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the categories\n",
        "encoder = LabelEncoder()\n",
        "category_encode = encoder.fit_transform(category)\n",
        "num_classes = len(encoder.classes_)\n",
        "\n",
        "\n",
        "\n",
        "# Print the mapping of categories to their encoded values\n",
        "print('Category encoding mapping:')\n",
        "for category, code in zip(encoder.classes_, encoder.transform(encoder.classes_)):\n",
        "    print(f'{category}: {code}')"
      ],
      "metadata": {
        "id": "qTjEuONn-VJR"
      },
      "id": "qTjEuONn-VJR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into 80% train and 20% combined test and validation sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(filtered_text_data, category_encode, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the remaining 20% into 10% test and 10% validation sets(X_temp and y_temp are the temporary filtered_text_data and labels shared from the training data)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n"
      ],
      "metadata": {
        "id": "Afqqa3f4G_Q_"
      },
      "id": "Afqqa3f4G_Q_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val[:3]"
      ],
      "metadata": {
        "id": "delOaBPH-o9i"
      },
      "id": "delOaBPH-o9i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val[:3]"
      ],
      "metadata": {
        "id": "8qbrEBLO_3gw"
      },
      "id": "8qbrEBLO_3gw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))\n",
        "print(len(X_test), len(y_test))"
      ],
      "metadata": {
        "id": "r_DyCC6SDz_o"
      },
      "id": "r_DyCC6SDz_o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first three training categories\n",
        "y_train[:3]"
      ],
      "metadata": {
        "id": "-sSNoQfiKWYI"
      },
      "id": "-sSNoQfiKWYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coverting the training, testing and validation set to numpy array\n",
        "\n",
        "X_train_nnlm = np.array(X_train)\n",
        "X_val_nnlm = np.array(X_val)\n",
        "X_test_nnlm = np.array(X_test)"
      ],
      "metadata": {
        "id": "8fnAwSFbMHOx"
      },
      "id": "8fnAwSFbMHOx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using _1 for model 1 which is nnlm-en-dim128-with-normalization\n",
        "\n",
        "# Creating the embedding matrix using nnlm-en-dim128-with-normalization\n",
        "\n",
        "embedding_dim = 128\n",
        "embedding_layer_1 = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\",\n",
        "    input_shape=[],\n",
        "    dtype=tf.string,\n",
        "    trainable=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "YV3BQA8ebNVS"
      },
      "id": "YV3BQA8ebNVS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "\n",
        "model_1 = tf.keras.Sequential([\n",
        "    embedding_layer_1,\n",
        "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "id": "ZoIeontkga2l"
      },
      "id": "ZoIeontkga2l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b285c382",
      "metadata": {
        "id": "b285c382"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "# Create the Adam optimizer with the specified learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed444c6d",
      "metadata": {
        "id": "ed444c6d"
      },
      "outputs": [],
      "source": [
        "#define early stopping criteria\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "# Train the model\n",
        "history_1 = model_1.fit(\n",
        "    X_train_nnlm, y_train,\n",
        "    validation_data=(X_val_nnlm, y_val),\n",
        "    epochs=10, batch_size=512, verbose=1, callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# converting the X_test_nnlm and y_test(which is still the same) to X_test and y_test to work with the code for evaluation, prediction and performance matrics\n",
        "X_test = X_test_nnlm\n",
        "y_test = y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model with the test data\n",
        "\n",
        "results_1 = model_1.evaluate(X_test, y_test)\n",
        "\n",
        "print(results_1)"
      ],
      "metadata": {
        "id": "Ku0rpcNalT57"
      },
      "id": "Ku0rpcNalT57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting with the test data\n",
        "\n",
        "results_pred_1 = model_1.predict(X_test)"
      ],
      "metadata": {
        "id": "CI7Oqvv_ttT-"
      },
      "id": "CI7Oqvv_ttT-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict_1 = history_1.history\n",
        "history_dict_1.keys()"
      ],
      "metadata": {
        "id": "SB7FZCZGttX_"
      },
      "id": "SB7FZCZGttX_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignig values to the history dictionary to the metrics variable\n",
        "acc_1 = history_dict_1['accuracy']\n",
        "val_acc_1 = history_dict_1['val_accuracy']\n",
        "loss_1 = history_dict_1['loss']\n",
        "val_loss_1 = history_dict_1['val_loss']\n",
        "\n",
        "epochs_1 = range(1, len(acc_1) + 1)\n",
        "\n",
        "# Ploting the graph for training and validation loss vs epochs\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs_1, loss_1, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs_1, val_loss_1, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Ff2npcRttch"
      },
      "id": "-Ff2npcRttch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting the graph for training and validation accuracy vs epochs\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs_1, acc_1, 'bo', label='Training acc')\n",
        "plt.plot(epochs_1, val_acc_1, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pu3f3CsEttgL"
      },
      "id": "pu3f3CsEttgL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to 1D numpy array\n",
        "y_pred_1 = np.argmax(results_pred_1, axis=1)\n",
        "\n",
        "# Assign y_test value to y_true\n",
        "y_true_1 = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_1 = confusion_matrix(y_true_1, y_pred_1)\n",
        "print(\"Confusion Matrix:\\n\", cm_1, \"\\n\")\n",
        "\n",
        "# Accuracy\n",
        "accuracy_1 = accuracy_score(y_true_1, y_pred_1)\n",
        "print(\"Accuracy:\", accuracy_1, \"\\n\")\n",
        "\n",
        "# ROC-AUC Score (One-vs-Rest approach)\n",
        "\n",
        "y_true_binarized = label_binarize(y_true_1, classes=[0, 1, 2, 3])\n",
        "y_pred_binarized = label_binarize(y_pred_1, classes=[0, 1, 2, 3])\n",
        "roc_auc_1 = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
        "print(\"ROC-AUC Score:\", roc_auc_1, \"\\n\")\n",
        "\n",
        "# Precision\n",
        "precision_1 = precision_score(y_true_1, y_pred_1, average='weighted')\n",
        "print(\"Precision:\", precision_1, \"\\n\")\n",
        "\n",
        "# Recall\n",
        "recall_1 = recall_score(y_true_1, y_pred_1, average='weighted')\n",
        "print(\"Recall:\", recall_1, \"\\n\")\n",
        "\n",
        "# F1 Score\n",
        "f1_1 = f1_score(y_true_1, y_pred_1, average='weighted')\n",
        "print(\"F1 Score:\", f1_1, \"\\n\")\n",
        "\n",
        "# Cohen's Kappa\n",
        "kappa_1 = cohen_kappa_score(y_true_1, y_pred_1)\n",
        "print(\"Cohen's Kappa:\", kappa_1, \"\\n\")\n",
        "\n",
        "# Matthews Correlation Coefficient (MCC)\n",
        "mcc_1 = matthews_corrcoef(y_true_1, y_pred_1)\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc_1, \"\\n\")\n",
        "\n",
        "# Classification Report\n",
        "report_1 = classification_report(y_true_1, y_pred_1)\n",
        "print(\"Classification Report:\\n\", report_1)\n"
      ],
      "metadata": {
        "id": "vaPZsMT2ttsJ"
      },
      "id": "vaPZsMT2ttsJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the confusion matrix\n",
        "cm_1 = confusion_matrix(y_true_1, y_pred_1)\n",
        "\n",
        "# Create a heatmap from the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.set(font_scale=1.4)  # for label size\n",
        "sns.heatmap(cm_1, annot=True, annot_kws={\"size\": 16}, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'],\n",
        "            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'])\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BKqLtQG4t6Zr"
      },
      "id": "BKqLtQG4t6Zr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics scores\n",
        "metrics = ['Accuracy', 'AUC/ROC', 'Precision', 'Recall', 'F1 score', 'Kappa', 'MCC']\n",
        "scores_1 = [accuracy_1, roc_auc_1, precision_1, recall_1, f1_1, kappa_1, mcc_1]\n",
        "\n",
        "# Set the desired figure size (width, height)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(metrics, scores_1, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Evaluation metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Model evaluation metrics')\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NTfNe8P-t6d2"
      },
      "id": "NTfNe8P-t6d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert integer-encoded labels to one-hot vectors\n",
        "y_train_use = to_categorical(y_train)\n",
        "y_val_use = to_categorical(y_val)\n",
        "y_test_use = to_categorical(y_test)\n",
        "\n",
        "\n",
        "# Coverting the training, testing and validation set to numpy array\n",
        "\n",
        "X_train_use = np.array(X_train)\n",
        "X_val_use = np.array(X_val)\n",
        "X_test_use = np.array(X_test)\n",
        "\n",
        "# Load the Universal Sentence Encoder\n",
        "use = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", trainable=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "LnqSQSBQuPSn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "LnqSQSBQuPSn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "\n",
        "# Define the model\n",
        "model_2 = Sequential()\n",
        "model_2.add(use)\n",
        "model_2.add(Dense(256, activation='relu'))\n",
        "model_2.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "\n",
        "\n",
        "# Provide an example batch to build the model\n",
        "example_inputs = tf.constant([\"series forms parallel comb tion keep mind total potential difference across resistors connected series sum individual potential differ en ces potential difference across resistors connected parallel every resistor equals potential difference across combination current resistors connected series every resistor equals current combination total current resistors connected parallel sum currents individual resistors evaluate answer check whether results cons tent equivalent resistance resistors connected series greater individual resistor res tors parallel less individual resistor equivalent resistance equivalent resistance network current resistor source emf negligible internal resistance solution identify set network resistors combination series parallel resistances determine steps reducing combination resistors single equivalent resistor ding current resistor continued\"], dtype=tf.string)\n",
        "model_2(example_inputs)\n",
        "\n",
        "# print the model summary.\n",
        "model_2.summary()\n"
      ],
      "metadata": {
        "id": "Sz_7RQ56-HV4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Sz_7RQ56-HV4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW1_rCON-HV4"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "# Create the Adam optimizer with the specified learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
      ],
      "id": "kW1_rCON-HV4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGRgzdTt-HV5"
      },
      "outputs": [],
      "source": [
        "#define early stopping criteria\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "# Train the model\n",
        "history_2 = model_2.fit(\n",
        "    X_train_use, y_train_use,\n",
        "    validation_data=(X_val_use, y_val_use),\n",
        "    epochs=10, batch_size=512, verbose=1, callbacks=[early_stop]\n",
        ")"
      ],
      "id": "vGRgzdTt-HV5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model with the test data\n",
        "\n",
        "results_2 = model_2.evaluate(X_test_use, y_test_use)\n",
        "\n",
        "print(results_2)"
      ],
      "metadata": {
        "id": "HXJ3-Veh-HV5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HXJ3-Veh-HV5"
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting with the test data\n",
        "\n",
        "results_pred_2 = model_2.predict(X_test_use)"
      ],
      "metadata": {
        "id": "o2-e3AEU-HV5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "o2-e3AEU-HV5"
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict_2 = history_2.history\n",
        "history_dict_2.keys()"
      ],
      "metadata": {
        "id": "Z0gDI8qE-HV5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Z0gDI8qE-HV5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignig values to the history dictionary to the metrics variable\n",
        "acc_2 = history_dict_2['accuracy']\n",
        "val_acc_2 = history_dict_2['val_accuracy']\n",
        "loss_2 = history_dict_2['loss']\n",
        "val_loss_2 = history_dict_2['val_loss']\n",
        "\n",
        "epochs_2 = range(1, len(acc_2) + 1)\n",
        "\n",
        "# Ploting the graph for training and validation loss vs epochs\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs_2, loss_2, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs_2, val_loss_2, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Ic6noIz-HV5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_Ic6noIz-HV5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting the graph for training and validation accuracy vs epochs\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs_2, acc_2, 'bo', label='Training acc')\n",
        "plt.plot(epochs_2, val_acc_2, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EE3xxGVo-HV6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "EE3xxGVo-HV6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to 1D numpy array\n",
        "y_pred_2 = np.argmax(results_pred_2, axis=1)\n",
        "\n",
        "# Assign y_test value to y_true\n",
        "y_true_2 = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_2 = confusion_matrix(y_true_2, y_pred_2)\n",
        "print(\"Confusion Matrix:\\n\", cm_2, \"\\n\")\n",
        "\n",
        "# Accuracy\n",
        "accuracy_2 = accuracy_score(y_true_2, y_pred_2)\n",
        "print(\"Accuracy:\", accuracy_2, \"\\n\")\n",
        "\n",
        "# ROC-AUC Score (One-vs-Rest approach)\n",
        "\n",
        "y_true_binarized = label_binarize(y_true_2, classes=[0, 1, 2, 3])\n",
        "y_pred_binarized = label_binarize(y_pred_2, classes=[0, 1, 2, 3])\n",
        "roc_auc_2 = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
        "print(\"ROC-AUC Score:\", roc_auc_2, \"\\n\")\n",
        "\n",
        "# Precision\n",
        "precision_2 = precision_score(y_true_2, y_pred_2, average='weighted')\n",
        "print(\"Precision:\", precision_2, \"\\n\")\n",
        "\n",
        "# Recall\n",
        "recall_2 = recall_score(y_true_2, y_pred_2, average='weighted')\n",
        "print(\"Recall:\", recall_2, \"\\n\")\n",
        "\n",
        "# F1 Score\n",
        "f1_2 = f1_score(y_true_2, y_pred_2, average='weighted')\n",
        "print(\"F1 Score:\", f1_2, \"\\n\")\n",
        "\n",
        "# Cohen's Kappa\n",
        "kappa_2 = cohen_kappa_score(y_true_2, y_pred_2)\n",
        "print(\"Cohen's Kappa:\", kappa_2, \"\\n\")\n",
        "\n",
        "# Matthews Correlation Coefficient (MCC)\n",
        "mcc_2 = matthews_corrcoef(y_true_2, y_pred_2)\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc_2, \"\\n\")\n",
        "\n",
        "# Classification Report\n",
        "report_2 = classification_report(y_true_2, y_pred_2)\n",
        "print(\"Classification Report:\\n\", report_2)\n"
      ],
      "metadata": {
        "id": "OucFlL7k-HV6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OucFlL7k-HV6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the confusion matrix\n",
        "cm_2 = confusion_matrix(y_true_2, y_pred_2)\n",
        "\n",
        "# Create a heatmap from the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.set(font_scale=1.4)  # for label size\n",
        "sns.heatmap(cm_2, annot=True, annot_kws={\"size\": 16}, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'],\n",
        "            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'])\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JkfO6w2V-HV6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "JkfO6w2V-HV6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics scores\n",
        "metrics = ['Accuracy', 'AUC/ROC', 'Precision', 'Recall', 'F1 score', 'Kappa', 'MCC']\n",
        "scores = [accuracy_2, roc_auc_2, precision_2, recall_2, f1_2, kappa_2, mcc_2]\n",
        "\n",
        "# Set the desired figure size (width, height)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(metrics, scores, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Evaluation metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Model evaluation metrics')\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ygf5Baki-HV6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ygf5Baki-HV6"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# loading the bert model from tensorflow hub\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "bert_model_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\"\n",
        "bert_layer = hub.KerasLayer(bert_model_url, trainable=False)\n",
        "\n",
        "# tokenize the preprocessed text\n",
        "import bert\n",
        "from bert import tokenization\n",
        "from bert.tokenization import bert_tokenization\n",
        "\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "def tokenize_and_preprocess(text):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return input_ids\n",
        "\n",
        "def prepare_bert_input(text, max_seq_length):\n",
        "    input_ids = tokenize_and_preprocess(text)\n",
        "\n",
        "    # Truncate the input sequence if it's longer than the max_seq_length\n",
        "    if len(input_ids) > max_seq_length:\n",
        "        input_ids = input_ids[:max_seq_length]\n",
        "\n",
        "    # Pad the input sequence if it's shorter than the max_seq_length\n",
        "    elif len(input_ids) < max_seq_length:\n",
        "        pad_length = max_seq_length - len(input_ids)\n",
        "        input_ids += [0] * pad_length\n",
        "\n",
        "    # Create input_mask and segment_ids arrays\n",
        "    input_mask = [1 if token_id != 0 else 0 for token_id in input_ids]\n",
        "    segment_ids = [0] * max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids\n",
        "\n",
        "# define a function to get the input_id, input_mask and segment_id\n",
        "\n",
        "def process_dataset(texts, max_seq_length=128):\n",
        "    input_ids_list, input_mask_list, segment_ids_list = [], [], []\n",
        "\n",
        "    for text in texts:\n",
        "        input_ids, input_mask, segment_ids = prepare_bert_input(text, max_seq_length)\n",
        "        input_ids_list.append(input_ids)\n",
        "        input_mask_list.append(input_mask)\n",
        "        segment_ids_list.append(segment_ids)\n",
        "\n",
        "    return (\n",
        "        tf.constant(input_ids_list, dtype=tf.int32),\n",
        "        tf.constant(input_mask_list, dtype=tf.int32),\n",
        "        tf.constant(segment_ids_list, dtype=tf.int32),\n",
        "    )\n",
        "\n",
        "train_input_ids, train_input_mask, train_segment_ids = process_dataset(X_train)\n",
        "test_input_ids, test_input_mask, test_segment_ids = process_dataset(X_test)\n",
        "val_input_ids, val_input_mask, val_segment_ids = process_dataset(X_val)\n",
        "\n",
        "# There was an OOM error when trying to use the get_bert_embeddings_for_dataset function so processing data in smaller batches\n",
        "\n",
        "# define a function to extract from the entire dataset\n",
        "\n",
        "def get_bert_embeddings_for_dataset(input_ids, input_mask, segment_ids, batch_size=32):\n",
        "    num_examples = input_ids.shape[0]\n",
        "    embeddings_list = []\n",
        "\n",
        "    for start_idx in range(0, num_examples, batch_size):\n",
        "        end_idx = min(start_idx + batch_size, num_examples)\n",
        "        inputs = {\n",
        "            'input_word_ids': input_ids[start_idx:end_idx],\n",
        "            'input_mask': input_mask[start_idx:end_idx],\n",
        "            'input_type_ids': segment_ids[start_idx:end_idx]\n",
        "        }\n",
        "        batch_embeddings = bert_layer(inputs)['pooled_output']\n",
        "        embeddings_list.append(batch_embeddings)\n",
        "\n",
        "    embeddings = tf.concat(embeddings_list, axis=0)\n",
        "    return embeddings\n",
        "\n",
        "# Extract the embedding from the training, testing and validation set\n",
        "\n",
        "train_embeddings = get_bert_embeddings_for_dataset(train_input_ids, train_input_mask, train_segment_ids)\n",
        "test_embeddings = get_bert_embeddings_for_dataset(test_input_ids, test_input_mask, test_segment_ids)\n",
        "val_embeddings = get_bert_embeddings_for_dataset(val_input_ids, val_input_mask, val_segment_ids)\n",
        "\n",
        "# convert the encoded category that has been splitted in to training, testing and validation to TensorFlow tensors\n",
        "\n",
        "train_labels_tensor = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "test_labels_tensor = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
        "val_labels_tensor = tf.convert_to_tensor(y_val, dtype=tf.int32)\n",
        "\n",
        "# Now we create and train the model based on the bert embedding method\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "input_layer = Input(shape=(train_embeddings.shape[1],))\n",
        "hidden_layer = Dense(128, activation='relu')(input_layer)\n",
        "output_layer = Dense(len(encoder.classes_), activation='softmax')(hidden_layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "79nJuX87uPXH"
      },
      "execution_count": null,
      "outputs": [],
      "id": "79nJuX87uPXH"
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "learning_rate = 0.001\n",
        "# Create the Adam optimizer with the specified learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model_3.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#define early stopping criteria\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "# Train the model\n",
        "history_3 = model_3.fit(train_embeddings, train_labels_tensor,\n",
        "                    validation_data=(val_embeddings, val_labels_tensor),\n",
        "                    epochs=10, batch_size=32, verbose=1, callbacks=[early_stop])\n",
        "\n",
        "\n",
        "# converting the test_embeddings and test_labels_tensor to X_test and y_test to work with the code we use for the three NNLM embedding methods\n",
        "X_test_bert = test_embeddings\n",
        "y_test_bert = test_labels_tensor\n"
      ],
      "metadata": {
        "id": "BWPY63w7-zai"
      },
      "id": "BWPY63w7-zai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model with the test data\n",
        "\n",
        "results_3 = model_3.evaluate(X_test_bert, y_test_bert)\n",
        "\n",
        "print(results_3)"
      ],
      "metadata": {
        "id": "w0gClQp7-JuB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "w0gClQp7-JuB"
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting with the test data\n",
        "\n",
        "results_pred_3 = model_3.predict(X_test_bert)"
      ],
      "metadata": {
        "id": "5qitekyW-JuB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5qitekyW-JuB"
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict_3 = history_3.history\n",
        "history_dict_3.keys()"
      ],
      "metadata": {
        "id": "zVTj10W1-JuB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zVTj10W1-JuB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignig values to the history dictionary to the metrics variable\n",
        "acc_3 = history_dict_3['accuracy']\n",
        "val_acc_3 = history_dict_3['val_accuracy']\n",
        "loss_3 = history_dict_3['loss']\n",
        "val_loss_3 = history_dict_3['val_loss']\n",
        "\n",
        "epochs_3 = range(1, len(acc_3) + 1)\n",
        "\n",
        "# Ploting the graph for training and validation loss vs epochs\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs_3, loss_3, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs_3, val_loss_3, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g3JGeCN3-JuB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "g3JGeCN3-JuB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting the graph for training and validation accuracy vs epochs\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs_3, acc_3, 'bo', label='Training acc')\n",
        "plt.plot(epochs_3, val_acc_3, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5RO6c3tU-JuC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5RO6c3tU-JuC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to 1D numpy array\n",
        "y_pred_3 = np.argmax(results_pred_3, axis=1)\n",
        "\n",
        "# Assign y_test value to y_true\n",
        "y_true_3 = y_test_bert\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_3 = confusion_matrix(y_true_3, y_pred_3)\n",
        "print(\"Confusion Matrix:\\n\", cm_3, \"\\n\")\n",
        "\n",
        "# Accuracy\n",
        "accuracy_3 = accuracy_score(y_true_3, y_pred_3)\n",
        "print(\"Accuracy:\", accuracy_3, \"\\n\")\n",
        "\n",
        "# ROC-AUC Score (One-vs-Rest approach)\n",
        "\n",
        "y_true_binarized = label_binarize(y_true_3, classes=[0, 1, 2, 3])\n",
        "y_pred_binarized = label_binarize(y_pred_3, classes=[0, 1, 2, 3])\n",
        "roc_auc_3 = roc_auc_score(y_true_binarized, y_pred_binarized, multi_class='ovr')\n",
        "print(\"ROC-AUC Score:\", roc_auc_3, \"\\n\")\n",
        "\n",
        "# Precision\n",
        "precision_3 = precision_score(y_true_3, y_pred_3, average='weighted')\n",
        "print(\"Precision:\", precision_3, \"\\n\")\n",
        "\n",
        "# Recall\n",
        "recall_3 = recall_score(y_true_3, y_pred_3, average='weighted')\n",
        "print(\"Recall:\", recall_3, \"\\n\")\n",
        "\n",
        "# F1 Score\n",
        "f1_3 = f1_score(y_true_3, y_pred_3, average='weighted')\n",
        "print(\"F1 Score:\", f1_3, \"\\n\")\n",
        "\n",
        "# Cohen's Kappa\n",
        "kappa_3 = cohen_kappa_score(y_true_3, y_pred_3)\n",
        "print(\"Cohen's Kappa:\", kappa_3, \"\\n\")\n",
        "\n",
        "# Matthews Correlation Coefficient (MCC)\n",
        "mcc_3 = matthews_corrcoef(y_true_3, y_pred_3)\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc_3, \"\\n\")\n",
        "\n",
        "# Classification Report\n",
        "report_3 = classification_report(y_true_3, y_pred_3)\n",
        "print(\"Classification Report:\\n\", report_3)\n"
      ],
      "metadata": {
        "id": "iDNHpo7R-JuC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iDNHpo7R-JuC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the confusion matrix\n",
        "cm_3= confusion_matrix(y_true_3, y_pred_3)\n",
        "\n",
        "# Create a heatmap from the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.set(font_scale=1.4)  # for label size\n",
        "sns.heatmap(cm_3, annot=True, annot_kws={\"size\": 16}, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'],\n",
        "            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3'])\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ABsa7Lvk-JuC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ABsa7Lvk-JuC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics scores\n",
        "metrics = ['Accuracy', 'AUC/ROC', 'Precision', 'Recall', 'F1 score', 'Kappa', 'MCC']\n",
        "scores_3 = [accuracy_3, roc_auc_3, precision_3, recall_3, f1_3, kappa_3, mcc_3]\n",
        "\n",
        "# Set the desired figure size (width, height)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(metrics, scores_3, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Evaluation metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Model evaluation metrics')\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zCFTNpJK-JuC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zCFTNpJK-JuC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best model based on their accuracy\n",
        "best_model = ''\n",
        "if results_1[1] >= results_2[1] and results_1[1] >= results_3[1]:\n",
        "    best_model = 'NNLM-128'\n",
        "elif results_2[1] >= results_1[1] and results_2[1] >= results_3[1]:\n",
        "    best_model = 'USE'\n",
        "else:\n",
        "    best_model = 'BERT'\n",
        "\n",
        "# Print the best model\n",
        "print(f'{best_model} is the best model.')\n",
        "\n"
      ],
      "metadata": {
        "id": "YNGxMvKkZw1V"
      },
      "id": "YNGxMvKkZw1V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the Best model on unseen data\n",
        "\n",
        "if best_model == 'NNLM-128':\n",
        "    user_input = input(\"Enter your text: \")\n",
        "    preprocessed_input = preprocess_text(user_input)\n",
        "    input_array = np.array([preprocessed_input])\n",
        "    predictions = model_1.predict(input_array)\n",
        "    predicted_label = np.argmax(predictions, axis=-1)\n",
        "    predicted_class_name = encoder.inverse_transform(predicted_label)[0]\n",
        "    print(f\"The input text belongs to the category: {predicted_class_name}\")\n",
        "    print(\"Predicted with NNLM-128 Model\")\n",
        "\n",
        "\n",
        "elif best_model == 'USE':\n",
        "    user_input_2 = input(\"Enter your text: \")\n",
        "    preprocessed_input_2 = preprocess_text(user_input_2)\n",
        "    input_array_2 = np.array([preprocessed_input_2])\n",
        "    predictions_2 = model_2.predict(input_array_2)\n",
        "    predicted_label_2 = np.argmax(predictions_2, axis=-1)\n",
        "    predicted_class_name_2 = encoder.inverse_transform(predicted_label_2)[0]\n",
        "    print(f\"The input text belongs to the category: {predicted_class_name_2}\")\n",
        "    print(\"Predicted with USE Model\")\n",
        "\n",
        "else:\n",
        "    user_input_3 = input(\"Enter your text: \")\n",
        "    user_input_ids, user_input_mask, user_segment_ids = process_dataset(user_input_3)\n",
        "    user_input_embeddings = get_bert_embeddings_for_dataset(user_input_ids, user_input_mask, user_segment_ids)\n",
        "    predictions_3 = model_3.predict(user_input_embeddings)\n",
        "    predicted_label_3 = np.argmax(predictions_3, axis=-1)\n",
        "    predicted_label_3 = predicted_label_3.reshape((1, len(predicted_label_3)))\n",
        "    predicted_class_name_3 = encoder.inverse_transform(predicted_label_3)[0]\n",
        "    print(f\"The input text belongs to the category: {predicted_class_name_3}\")\n",
        "    print(\"Predicted with BERT Model\")"
      ],
      "metadata": {
        "id": "SQEoYTxp5MQT"
      },
      "id": "SQEoYTxp5MQT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
